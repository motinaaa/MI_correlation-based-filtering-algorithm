---
title: "Creating the ``r params$MIFilter`` R package"
date: "04-13-2023"
knit: litr::render
output: litr::litr_html_document
params:
  package_name: "MIFilter" # <-- change this to your package name
  package_parent_dir: "." # <-- relative to this file's location
---

```{=html}
<!-- This Rmd file contains all the code needed to define an R package.  Press "Knit" in RStudio or more generally run `litr::render("name-of-this-file.Rmd")` to generate the R package.  Remember that when you want to modify anything about the R package, you should modify this document rather than the package that is outputted.
-->
```


## Package setup

We start by specifying the information needed in the DESCRIPTION file of the R package.

```{r package-setup, message=FALSE, results='hide'}
usethis::create_package(
  path = ".",
  fields = list(
    Package = params$package_name,
    Version = "0.0.0.9000",
    Title = "MIFilter",
    Description = "This package include some functions that allow the users to analyze their datasets with many features based on MI and correlation values, and get rid of extra unuseful features. This package contains a dataset as an example.",
    `Authors@R` = c(person(
      given = "Atefeh",
      family = "Anisi",
      email = "anisi@iastate.edu",
      role = c("aut", "cre")
      ),
      person(
      given = "Parvin",
      family = "Mohammadiarvejeh",
      email = "pmohamm@iastate.edu",
      role = c("aut")
      ),
      person(
      given = "Motina",
      family = "Kashanian",
      email = "motinaa@iastate.edu",
      role = c("aut")
      ))
  )
)

usethis::use_mit_license(copyright_holder = "M. Kashanian")
usethis::use_package("magrittr")
usethis::use_package("mpmi")
usethis::use_package("dataPreparation")
usethis::use_package("plotly")
usethis::use_package("readr")
usethis::use_package("purrr")
usethis::use_package("graphics")
usethis::use_package("stats")
```



## Now to the package itself

`correlation_based_filtering(X_train, y_train, MI_threshold, cor_threshold, X_test)` takes some values as input and returns a list of lists. This list contains three outputs which are reduced X_train, reduced X_test and the names of the remaining features.

```{r,eval=TRUE}
#' lallalalallala
#'
#' @importFrom stats cor
#' @importFrom mpmi mmi
#'
#' @param X_train features in training data (Original X_train)
#' @param y_train class variable for training set
#' @param MI_threshold which is a threshold for the mutual information score between the features (X_train) and the response variable (y_train)
#' @param cor_threshold which is a threshold for the linear correlation between the features (X_train)
#' @param X_test features in test data (Original X_test)
#'
#' @return a list of lists with three outputs which are the reduced_X_train, reduced_X_test and features_list.
#' @export
correlation_based_filtering = function(X_train, y_train, MI_threshold, cor_threshold, X_test){


  # Output:
  # 1) $x1 = reduced_X_train which is the reduced X_train
  # 2) $x2 = reduced_X_test which is the reduced X_test
  # 3) $x3 = features_list which is the list of selected features


  # Get the MI scores between the features (continuous) in X_train and y_train (discrete)
  mmi_output = mpmi::mmi(cts = X_train, disc = y_train)
  mmi_scores_output = mmi_output$mi
  MI_scores = as.vector(mmi_scores_output)


  # Get the indices of the features that they have MI_scores more than the MI_threshold
  True_index = which(MI_scores > MI_threshold)

  # Reduced the X_train by choosing the features in True_index
  reduced_X_train_one = X_train[, True_index]






  # Get the MI scores between the remained features (continuous) and the y_train (discrete)
  new_mmi_output = mpmi::mmi(cts = reduced_X_train_one, disc = y_train)
  new_mmi_scores_output = new_mmi_output$mi
  final_MI_scores = as.vector(new_mmi_scores_output)
  # Sort the final_MI_scores
  inds = order(final_MI_scores, decreasing = FALSE)
  # Order the reduced X_train based on ascending order of MI scores of features with y_train
  reduced_X_train_one = reduced_X_train_one[, inds]






  # Get the names of columns in reduced_X_train_one and make a list by them
  features_list = t(t(colnames(reduced_X_train_one)))
  features_list = as.vector(features_list)
  # Get the number of the features (columns names) in the list
  num_features = length(features_list)





  for ( e in 1:num_features){# e is the index of the features in feature list starting from first feature
    q = e + 1   # q is the index of the features which is next (after) to the feature with index e
    while (q <= num_features){# while loop to check correlation between the pairs
      if (abs(stats::cor(reduced_X_train_one[, e], reduced_X_train_one[, q])) > cor_threshold){
        q = q + 1 # update q
        num_features = num_features - 1 # decrease the num_features if the threshold is passed
        for (i in (q-2):num_features){
          features_list[i] = features_list[(i+1)] # Update the feature list
        }
        features_list = features_list[-(num_features + 1) ] # drop the last element in the feature list

      }else{
        q = q + 1 # Update q

      }

    }
    e = e + 1 # Update e
  }



  # Select the columns in the final feature list from the train data set
  reduced_X_train = reduced_X_train_one[, features_list]


  # Select the columns in the final feature list from the test data set
  reduced_X_test = X_test[, features_list]

  # Make a list by features_list and final train and test data set
  output_filtering_list = list(x1 = reduced_X_train, x2 = reduced_X_test, x3 = features_list)

  return(output_filtering_list)

}


```


Standardization of the train and test set function. This function gets the train set, fit the standardizer to the train set, then it applies the fitted standardizer to the test set.

```{r,eval=FALSE}
#' lallalalallala
#'
#' @importFrom dataPreparation build_scales
#' @importFrom dataPreparation fast_scale
#'
#' @param X_train  features in training data (in this project X_train is the reduced_X_train)
#' @param X_test features in test data (in this project X_test is the reduced_X_test)
#'
#' @return a list which contains the standardized version of X_train and X_test.
#' @export
scaling_train_test = function(X_train, X_test){



  # Output:
  # 1) $y1 = scaled_X_train (in this project scaled_X_train is the standardized reduced_X_train)
  # 2) $y2 = scaled_X_test (in this project scaled_X_train is the standardized reduced_X_train)





  # Prepare the scaling function which will be fitted n the train set
  scaling_fit = dataPreparation::build_scales(data_set = X_train, cols = "auto", verbose = TRUE)
  # Get the new X_train
  scaled_X_train = dataPreparation::fast_scale(data_set = X_train, scales = scaling_fit, verbose = TRUE)
  # Apply the scaling_fit function (which have been fitted to the train set) to the test set
  scaled_X_test = dataPreparation::fast_scale(data_set = X_test, scales = scaling_fit, verbose = TRUE)




  # Make a list by X_train and X_test
  output_standardization_list = list(y1 = scaled_X_train, y2 = scaled_X_test)


  return(output_standardization_list)
}
```


Now, we want to create two functions for the visualization purposes. The first one shows the relation between selected MI_threshold, number of remaining features and the mean MI of the remaining features.

```{r,eval=FALSE}
#' lallalalallala
#'
#'@importFrom mpmi mmi
#'@importFrom plotly plot_ly
#'
#' @param MI_threshold_LB  which is the lower bound for the selected MI values
#' @param MI_threshold_UB which is the upper bound for the selected MI values
#' @param MI_threshold_step which is the step to produce MI values
#' @param X_train features in training data (original X_train)
#' @param y_train class variable for training set
#' @param X_test features in test data (original X_test)
#' @param cor_threshold which is a threshold for the linear correlation between the features (X_train)
#'
#' @return a data frame containing selected MI_values with their corresponding results for the mean_MI and the number of remaining features.
#' @return a 3D plot showing the result in data frame
#' @export
MI_analysis_plot = function(MI_threshold_LB,MI_threshold_UB,MI_threshold_step,X_train,y_train,X_test, cor_threshold){

  MI_threshold_values = seq(MI_threshold_LB, MI_threshold_UB, by=MI_threshold_step)

  plot_input = data.frame(matrix(ncol = 3, nrow = ((MI_threshold_UB - MI_threshold_LB)/MI_threshold_step) + 1))

  #provide column names
  colnames(plot_input) <- c('MI_threshold', 'No. features after reduction', 'Mean_MI')

  output = list()

  j = 1

  for (i in MI_threshold_values){

    plot_input [j,1] = i
    output= correlation_based_filtering(X_train, y_train, i, cor_threshold, X_test)
    plot_input [j,2] = length(output$x3)
    mmi_output = mpmi::mmi(cts = output$x1, disc = y_train)
    plot_input [j,3] = mean(as.vector(mmi_output$mi))
    j= j + 1
  }

  fig <- plotly::plot_ly(plot_input, x = plot_input[,1], y = plot_input[,2], z = plot_input[,3], colors = c('#0C4B8E'))
  fig <- fig %>% add_markers()
  fig <- fig %>% layout(xaxis = list(title = 'MI_threshold'),
                                     yaxis = list(title = 'No. features'),
                                     zaxis = list(title = 'Mean_MI'))

  print (fig)
  return (plot_input)

}
```


Second plot shows the relationship between selected MI_thresholds, selected cor_thresholds, and the number of remaining features.

```{r,eval=FALSE}
#' lallalalallala
#'
#' @importFrom plotly plot_ly
#' @importFrom magrittr %>%
#' @importFrom  graphics layout
#' @importFrom plotly add_markers
#'
#' @param MI_threshold_LB  which is the lower bound for the selected MI values
#' @param MI_threshold_UB which is the upper bound for the selected MI values
#' @param MI_threshold_step which is the step to produce MI values
#' @param cor_threshold_LB which is the lower bound for the selected cor values
#' @param cor_threshold_UB which is the upper bound for the selected cor values
#' @param cor_threshold_step which is the step to produce cor values
#' @param X_train features in training data (original X_train)
#' @param y_train class variable for training set
#' @param X_test features in test data (original X_test)
#'
#' @return a data frame containing selected MI_values and cor_values with their corresponding results for the number of remaining features.
#' @return a 3D plot showing the result in data frame
#' @export
MI_cor_plot = function(MI_threshold_LB,MI_threshold_UB,MI_threshold_step,cor_threshold_LB,cor_threshold_UB,cor_threshold_step,X_train,y_train,X_test){

  cor_threshold_values = seq(cor_threshold_LB, cor_threshold_UB, by=cor_threshold_step)
  MI_threshold_values = seq(MI_threshold_LB, MI_threshold_UB, by=MI_threshold_step)

  plot_input = data.frame(matrix(ncol = 3, nrow = (length(cor_threshold_values)*length(MI_threshold_values))))

  #provide column names
  colnames(plot_input) <- c('cor_threshold', 'MI_threshold','No. features after reduction')

  output = list()

  j = 1

  for (i in cor_threshold_values){

    for (f in MI_threshold_values){

      plot_input [j,1] = i
      plot_input [j,2] = f
      output= correlation_based_filtering(X_train, y_train, f, i, X_test)
      plot_input [j,3] = length(output$x3)
      j= j + 1
    }
  }


  fig <- plotly::plot_ly(plot_input, x = plot_input[,1], y = plot_input[,2], z = plot_input[,3], colors = c('#0C4B8E'))
  fig <- fig %>% plotly::add_markers()
  fig <- fig %>% graphics::layout(scene = list(xaxis = list(title = 'cor_threshold'),
                                     yaxis = list(title = 'MI_threshold'),
                                     zaxis = list(title = 'No. features after reduction')))

  print(fig)
  return (plot_input)

}
```

### Create a Data Set

To create a dataset we should do a call. The rest of the code will run to create documentation.
```{r,eval=FALSE}
#'@importfrom readr read_csv
#'@importfrom purrr map_df

X_train = list.files("../data",
                           pattern="X_train",
                           full.names=T)# read only ending in csv
X_test = list.files("../data",
                           pattern="X_test",
                           full.names=T)# read only ending in csv
y_train = list.files("../data",
                           pattern="y_train",
                           full.names=T)# read only ending in csv
y_test = list.files("../data",
                           pattern="y_test",
                           full.names=T)# read only ending in csv


# reading data from csv files
X_train <-purrr::map_df(X_train,~readr::read_csv(.,show_col_types = F))
X_test <-purrr::map_df(X_test,~readr::read_csv(.,show_col_types = F))
y_train <-purrr::map_df(y_train,~readr::read_csv(.,show_col_types = F))
colnames(y_train)[1] = "class"
y_test <-purrr::map_df(y_test,~readr::read_csv(.,show_col_types = F))
colnames(y_test)[1] = "class"
  
```

```{r,eval=FALSE}
#'@importfrom usethis use_data
usethis::use_data(X_train)
usethis::use_data(X_test)
usethis::use_data(y_train)
usethis::use_data(y_test)
```


And we'll need to document the data set as well and describe it:

```{r,eval=FALSE}
#' A X_train data set
#' 
#' @format A data frame of all the features in training set 
#' 
"X_train"
```

```{r,eval=FALSE}
#' A X_test data set
#' 
#' @format A data frame of all the features in test set 
#' 
"X_test"
```

```{r,eval=FALSE}
#' A y_train data set
#' 
#' @format A column which contains the class or the response variable in the training set 
#' \describe{
#'  \item{class}{the class variable}
#' }
#' 
"y_train"
```

```{r,eval=FALSE}
#' A y_test data set
#' 
#' @format A column which contains the class or the response variable in the test set 
#' \describe{
#'  \item{class}{the class variable}
#' }
#' 
"y_test"
```

## Documenting the package and building

We finish by running commands that will document, build, and install the package. It may also be a good idea to check the package from within this file.

```{r,eval=FALSE}
#'@importfrom devtools document
devtools::document() # <-- use instead of devtools::document()
#devtools::build()
#devtools::install()
#devtools::check(document = FALSE)
```
Footer
© 2023 GitHub, Inc.
Footer navigation
Terms
Privacy
Security
Status
Docs
Contact GitHub
Pricing
API
Training
Blog
About





